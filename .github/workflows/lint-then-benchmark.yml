name: Lint and then Benchmark


on:
  pull_request:

  push:
    tags:
      - v*
    branches:
      - master
      - develop


## These are the permissions for the lint check job.
permissions:
  # Allow read access to pull request (Required for the `only-new-issues` option.)
  pull-requests: read
  contents: read


env:
  # This can be modified to one of 'NONE', 'FULL', 'SHORT'. [Defaut = 'SHORT']
  BENCHMARK_TYPE: SHORT


jobs:


  # ========================================================= Step-1: Run the lint check.
  golangci:
    name: Lint Check
    strategy:
      matrix:
        os: [ubuntu-latest]

    runs-on: ${{ matrix.os }}

    steps:
      - name: Check out code into the directory
        uses: actions/checkout@v2

      - name: Run the golangci-lint
        uses: golangci/golangci-lint-action@v2

        with:
          # Required: the version of golangci-lint is required.
          # Note: The version should not pick the patch version as the latest patch
          #  version is what will always be used.
          version: v1.44

          # Optional: working directory, useful for monorepos or if we wanted to run this
          #  on a non-root directory.
          # working-directory: ./

          # Optional: golangci-lint command line arguments.
          # Note: we can set `--issues-exit-code=0` if we want a successcode always,
          #  indicating that the linter ran successfully (weather or not linter errors
          #  exist or not doesn't matter). But the good think is that the annotations
          #  will still show up. I think this can be useful if we don't want the pipeline
          #  to stop just because we had some linter errors. 
          args: --issues-exit-code=1 --config .golangci.sourceinc.yaml

          # Optional: we can set the below to `true` if we only want to see newly
          #  introduced linter errors, however I found that in practive that option is a
          #  bit gimmicky, as it passes the linter check despite having new linter errors
          #  in some cases. So we opt in for all annotations of linter errors to show up,
          #  this is actually nicer because we suppress our linter errors manually
          #  anyways so there shouldn't be any linter errors anyways. The enforces us to
          #  always have a clean lint state.
          only-new-issues: false


  # This job acts like a switch to simplify our ci control flow later on.
  decide-benchmark-type:
    name: Deciding which benchmarks to run based on flags.
    strategy:
      matrix:
        os: [ubuntu-latest]

    runs-on: ${{ matrix.os }}

    needs:
      - golangci # only run if the linter check passed.

    steps:
      - name: Check for full benchmark label.
        if: |
          github.event.action == 'labeled' &&
          contains(github.event.pull_request.labels.*.name, 'full-benchmark')
        run: |
          echo "BENCHMARK_TYPE=FULL" >> ${GITHUB_ENV}

      - name: Check for label that skips the benchmark.
        if: |
          github.event.action == 'labeled' &&
          contains(github.event.pull_request.labels.*.name, 'no-benchmark')
        run: |
          echo "BENCHMARK_TYPE=NONE" >> ${GITHUB_ENV}


  # ================== Step-2: Start the runner and get it registered as a github runner.
  start-runner:
    name: Start self-hosted EC2 runner

    needs:
      - golangci # only run if the linter check passed.
      - decide-benchmark-type # type of benchmark to run.

    runs-on: ubuntu-latest

    outputs:
      label: ${{ steps.start-ec2-runner.outputs.label }}
      ec2-instance-id: ${{ steps.start-ec2-runner.outputs.ec2-instance-id }}

    steps:

      - name: Configure AWS credentials
        if: env.BENCHMARK_TYPE != 'NONE'
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Start EC2 runner
        if: env.BENCHMARK_TYPE != 'NONE'
        id: start-ec2-runner
        uses: machulav/ec2-github-runner@v2
        with:
          mode: start
          github-token: ${{ secrets.REPO_SCOPE_PAT }}
          ec2-image-id: ${{ secrets.EC2_IMAGE_ID }}
          ec2-instance-type: t3.xlarge
          subnet-id: ${{ secrets.SUBNET_ID }}
          security-group-id: ${{ secrets.SECURITY_GROUP_ID }}
          ## iam-role-name: my-role-name # optional, requires additional permissions
          ## aws-resource-tags: > # optional, requires additional permissions
          ##   [
          ##     {"Key": "Name", "Value": "ec2-github-runner"},
          ##     {"Key": "GitHubRepository", "Value": "${{ github.repository }}"}
          ##   ]


  # ============================Step-3: Run the benchmarks on the runner we just started.
  benchmark-ec2-runner:
    name: Run the benchmarks on the started EC2 runner

    needs:
      - golangci # only run if the linter check passed.
      - decide-benchmark-type # type of benchmark to run.
      - start-runner # required to start the main job when the runner is ready.

    runs-on: ${{ needs.start-runner.outputs.label }} # run the job on the newly created runner

    env:
      # This is also the same directory as `$GITHUB_WORKSPACE/..`
      HOME: /actions-runner/_work
      GOPATH: /actions-runner/_work/go

    steps:
      - name: Checkout code
        if: env.BENCHMARK_TYPE != 'NONE'
        uses: actions/checkout@v2

      - name: Run the full bechmarking suite
        if: ${{ env.BENCHMARK_TYPE == 'FULL' }}
        run: make test:bench

      - name: Run only the shorter benchmarks
        if: ${{ env.BENCHMARK_TYPE == 'SHORT' }}
        run: make test:bench-short


  # =============================== Step-4: Stop the runner once the benchmarks have ran.
  stop-runner:
    name: Stop self-hosted EC2 runner

    needs:
      - golangci # only run if the linter check passed.
      - decide-benchmark-type # type of benchmark to run.
      - start-runner # required to get output from the start-runner job.
      - benchmark-ec2-runner # required to wait when the main job is done.

    # Stop the runner even if an error happened in the previous jobs. Also ensure that
    #  if the EC2 runner was actually started, only then we stop it.
    if: |
      always() &&
      needs.start-runner.result == 'success'

    runs-on: ubuntu-latest

    steps:

      - name: Configure AWS credentials
        if: env.BENCHMARK_TYPE != 'NONE'
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Stop EC2 runner
        if: env.BENCHMARK_TYPE != 'NONE'
        uses: machulav/ec2-github-runner@v2
        with:
          mode: stop
          github-token: ${{ secrets.REPO_SCOPE_PAT }}
          label: ${{ needs.start-runner.outputs.label }}
          ec2-instance-id: ${{ needs.start-runner.outputs.ec2-instance-id }}
